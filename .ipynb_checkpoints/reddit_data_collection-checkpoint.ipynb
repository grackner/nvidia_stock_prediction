{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HerP6rOxlTVZ"
   },
   "source": [
    "# Collecting Reddit Data with Reddit API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YsHbs29BNcTc",
    "outputId": "cd13b6ef-2175-47e9-d77e-555ca30a0b1d"
   },
   "outputs": [],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIPXFk75eOO_"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import praw\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AaVTX2dExsV2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv('x.env')\n",
    "\n",
    "# Set up credentials from env file\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.getenv(\"CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"CLIENT_SECRET\"),\n",
    "    user_agent=os.getenv(\"USER_AGENT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXrPmRvbgRSP"
   },
   "source": [
    "### Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9q2dbc-_RhP8",
    "outputId": "2eac8ff2-c5e6-4b7a-bb80-4f1756082253"
   },
   "outputs": [],
   "source": [
    "# Get training data range\n",
    "start_date = datetime.datetime(2024, 11, 1)  # November 1, 2024\n",
    "end_date = datetime.datetime(2025, 1, 31)  # January 31, 2025\n",
    "\n",
    "# Convert datetime dates to Unix timestamps\n",
    "start_timestamp = int(start_date.timestamp())\n",
    "end_timestamp = int(end_date.timestamp())\n",
    "\n",
    "# Query subreddit posts containing 'NVIDIA' within the date range in various subreddits\n",
    "subreddits = ['stocks', 'investing', 'money', 'DayTrading', 'wallstreetbets']\n",
    "# Create filtered posts list\n",
    "train_filtered_posts = []\n",
    "# Loop through subreddits\n",
    "for subreddit in subreddits:\n",
    "  curr_subreddit = reddit.subreddit(subreddit)\n",
    "\n",
    "  # Search query with a time filter (limit to posts from Nov-Jan)\n",
    "  posts = curr_subreddit.search(\"NVIDIA\",\n",
    "                            sort='new',\n",
    "                            time_filter='all',\n",
    "                            limit=None)\n",
    "  # Loop through search results, if they are within time period, add to the list\n",
    "  for post in posts:\n",
    "      post_date = datetime.datetime.utcfromtimestamp(post.created_utc)\n",
    "      if start_timestamp <= post.created_utc <= end_timestamp:\n",
    "          train_filtered_posts.append({\n",
    "              'Post_Title': post.title,\n",
    "              'Post_URL': post.url,\n",
    "              'Post_Text': post.selftext,\n",
    "              'Date_Posted': post_date,\n",
    "              'Upvotes': post.score,\n",
    "              'Comments': post.num_comments,\n",
    "              'Subreddit': post.subreddit.display_name,\n",
    "          })\n",
    "\n",
    "# Convert the list of dictionaries to pandas df\n",
    "train_reddit_df = pd.DataFrame(train_filtered_posts)\n",
    "\n",
    "print(len(train_reddit_df))\n",
    "train_reddit_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxuQUMNLRqc8"
   },
   "outputs": [],
   "source": [
    "train_reddit_df.to_csv('data/train_reddit_df_w_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2BVOUOQTD_X"
   },
   "source": [
    "### Get Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vAU3Aw1CRuMW",
    "outputId": "cbe07f72-9b41-4779-fa01-fc7a3450a93e"
   },
   "outputs": [],
   "source": [
    "# Get test data range\n",
    "start_date = datetime.datetime(2025, 2, 1)  # February, 1, 2025\n",
    "end_date = datetime.datetime(2025, 2, 7)  # February, 7, 2025\n",
    "\n",
    "start_timestamp = int(start_date.timestamp())\n",
    "end_timestamp = int(end_date.timestamp())\n",
    "\n",
    "# Query subreddit posts containing 'NVIDIA' within the date range in various subreddits\n",
    "subreddits = ['stocks', 'investing', 'money', 'DayTrading', 'wallstreetbets']\n",
    "test_filtered_posts = []\n",
    "for subreddit in subreddits:\n",
    "  curr_subreddit = reddit.subreddit(subreddit)\n",
    "\n",
    "  # Search query with a time filter (limit to posts from Feb1-Feb7)\n",
    "  posts = curr_subreddit.search(\"NVIDIA\",\n",
    "                            sort='new',\n",
    "                            time_filter='all',\n",
    "                            limit=None)\n",
    "  # Loop through search results, append if within desired time range\n",
    "  for post in posts:\n",
    "      post_date = datetime.datetime.utcfromtimestamp(post.created_utc)\n",
    "      if start_timestamp <= post.created_utc <= end_timestamp:\n",
    "          test_filtered_posts.append({\n",
    "              'Post_Title': post.title,\n",
    "              'Post_URL': post.url,\n",
    "              'Post_Text': post.selftext,\n",
    "              'Date_Posted': post_date,\n",
    "              'Upvotes': post.score,\n",
    "              'Comments': post.num_comments,\n",
    "              'Subreddit': post.subreddit.display_name,\n",
    "          })\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "test_reddit_df = pd.DataFrame(test_filtered_posts)\n",
    "\n",
    "print(len(test_reddit_df))\n",
    "test_reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBNG5EKYT7Ny"
   },
   "outputs": [],
   "source": [
    "test_reddit_df.to_csv('data/test_reddit_df_w_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WAMQKINTT8d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
